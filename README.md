# ğŸ§¬ EL Pipeline with Docker Compose

A fully managed Extractâ€“Load (EL) data pipeline built with Python and PostgreSQL, containerized with Docker Compose for seamless deployment and management.
This setup ensures secure credential handling, persistent storage, and automated scheduling for both data extraction and database backups.

![gif](assets/farmnews_docker.gif "architecture diagram")

## ğŸš€ Overview

1. This project automates the process of:

2. Extracting data via a Python script from a defined source (API, files, etc.).

3. Loading the transformed data into a PostgreSQL database.

4. Scheduling pipeline runs and database backups using cron jobs.

5. Securing credentials and ensuring data persistence across container restarts.

The entire system runs on the same server within isolated Docker containers, orchestrated through Docker Compose.

```bash
FARM_NEWS/
â”‚
â”œâ”€â”€ .venv/                     # Your virtual environment (auto-generated)
â”‚
â”œâ”€â”€ dev/                       # Development environment folder
â”‚   â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ .env                   # Dev-specific environment variables
â”‚
â”œâ”€â”€ prod/                      # Production environment folder
â”‚   â”œâ”€â”€ credentials/
â”‚   â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ docker-compose.yml     # Likely prod deployment setup
â”‚
â”œâ”€â”€ app.ipynb                  # Notebook (for experimentation)
â”œâ”€â”€ app.py                     # Main application / entrypoint script
â”œâ”€â”€ here.csv                   # Local test data file
â”œâ”€â”€ ingestion.log              # Log file (runtime generated)
â”œâ”€â”€ query.sql                  # SQL scripts for extraction or transformation
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

```
## ğŸ› ï¸ Key Features
### ğŸ”’ Secure Credential Management

Credentials are handled using Docker secrets, not environment variables.

This keeps sensitive information (e.g., database password, API keys) off container logs and images.


### ğŸ’¾ Data Persistence

Docker volumes ensure PostgreSQL and pipeline data persist between container restarts.

Database data and extracted results are never lost when containers are recreated.


### ğŸ“‚ Bind Mounts for Logs & Backups

Python script logs are written to a host-mounted directory (./logs).

PostgreSQL backups are stored in a bind-mounted folder (./backups) for easy external access.


### â° Automated Scheduling

A cron service triggers:

Daily pipeline runs to refresh the database.

Twice-daily PostgreSQL backups for data safety.

Each job runs inside its respective container with predefined intervals.